{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wgan_edit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFx0PZBrhsmC"
      },
      "source": [
        "# Train and Generate Blur Kernels\n",
        "\n",
        "This code trains a GAN based on WGAN architecture to generate synthetic blur kernels. The GAN is trained on kerenel approximated from low resolution images using Dark Channels.\n",
        "\n",
        "Code by by Ruofan Zhou, Sabine SÃ¼sstrunk with slight modifications for userbility.\n",
        "\n",
        "View the original Github Repo: \n",
        "[Kernel Modeling Super-Resolution on Real Low-Resolution Images](https://github.com/IVRL/Kernel-Modeling-Super-Resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y03SBZEQWedP"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwsX3np6x4Nl"
      },
      "source": [
        "from utils.wgan_clipping import WGAN_CP\n",
        "from utils.data_loader import FolderDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Modify MODEL_PATH to point to the directory to store the trained model\n",
        "    # IMG_OUT and INT_IMG point to directors to store images as the training progresses\n",
        "    save_path = {\n",
        "    'MODEL_PATH' : 'drive/My Drive/Models/',\n",
        "    'IMG_OUT' : 'drive/My Drive/ProgressImages/',\n",
        "    'INT_IMG' : 'drive/My Drive/IntImages/'\n",
        "    }\n",
        "\n",
        "    model = WGAN_CP(save_path,channels=1, generator_iters=400000)\n",
        "    dataset = 'drive/My Drive/Matlab/'\n",
        "    # modify the following line for the dataset folder\n",
        "    train_set = FolderDataset(dataset=dataset)\n",
        "    train_loader = DataLoader(dataset=train_set, num_workers=1, batch_size=128, shuffle=True)\n",
        "    \n",
        "    model.train(train_loader)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvDrPT3DWYdg"
      },
      "source": [
        "## Load Model and Generate Kernels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaLRXTesTFEI"
      },
      "source": [
        "from utils.wgan_clipping import WGAN_CP\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import time as t\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import os\n",
        "from utils.tensorboard_logger import Logger\n",
        "from torchvision import utils\n",
        "import numpy as np\n",
        "import cv2\n",
        "from scipy.io import savemat\n",
        "\n",
        "def normalize_kernel(k):\n",
        "    k = k.numpy()\n",
        "    k = np.clip(k, 0, 1)\n",
        "    k = k/sum(sum(k))\n",
        "    return k  \n",
        "\n",
        "# modify the following line to the folder of output\n",
        "outputdir = 'drive/My Drive/generated_kernels/'\n",
        "# modify the following line to the number of kernels that needs to be generated\n",
        "num_generate = 800\n",
        "\n",
        "if not os.path.exists(outputdir):\n",
        "    os.mkdir(outputdir)\n",
        "\n",
        "# loading model\n",
        "save_path = {\n",
        "    'MODEL_PATH' : 'drive/My Drive/Models/',\n",
        "    'IMG_OUT' : 'drive/My Drive/ProgressImages/',\n",
        "    'INT_IMG' : 'drive/My Drive/IntImages/'\n",
        "    }\n",
        "model = WGAN_CP(save_path)\n",
        "D_model_path = 'discriminator.pkl'\n",
        "G_model_path = 'generator.pkl'\n",
        "model.load_model(D_model_path, G_model_path)\n",
        "\n",
        "\n",
        "z = Variable(torch.randn(num_generate, 100, 1, 1)).cuda()\n",
        "samples = model.G(z)\n",
        "samples = samples.data.cpu()\n",
        "for i in range(num_generate):\n",
        "    kernel = normalize_kernel(samples[i, 0])\n",
        "    savemat('%s%d.mat'%(outputdir,i), {'kernel':kernel})\n",
        "    if i%100 == 0:\n",
        "      print('Completed {}'.format(i))\n",
        "\n",
        "        # for plotting\n",
        "    #kernel = kernel/np.max(kernel)\n",
        "    #cv2.imwrite('%s%d.png'%(outputdir,i), kernel*255)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}